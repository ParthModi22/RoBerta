{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BN-GNgPx_vZ6"
      },
      "outputs": [],
      "source": [
        "pip install streamlit -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hizIKY-q_yGS",
        "outputId": "e652882a-fb99-42b3-a467-d02beb5b36c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.247.155.250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import torch\n",
        "import requests\n",
        "from PIL import Image\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Load the processor and model\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\", torch_dtype=torch.float16).to(\"cuda\")\n",
        "\n",
        "# Define function for web search\n",
        "def search_web(query):\n",
        "    search_query = query.replace(' ', '+')\n",
        "    url = f'https://html.duckduckgo.com/html?q={search_query}'\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
        "    }\n",
        "    response = requests.get(url, headers=headers)\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        valid_urls = set()\n",
        "        for result in soup.find_all('a', href=True):\n",
        "            href = result['href']\n",
        "            if href.startswith('/l/') or 'duckduckgo.com' in href or 'about:' in href:\n",
        "                continue\n",
        "            if href.startswith('/'):\n",
        "                href = f'https://duckduckgo.com{href}'\n",
        "            valid_urls.add(href)\n",
        "        return valid_urls\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "# Define function to display results\n",
        "def display_results(results):\n",
        "    if results:\n",
        "        for i, result in enumerate(results):\n",
        "            st.write(f\"URL: {result}\")\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    # Streamlit UI\n",
        "    img = st.file_uploader('Upload Image', type=['jpg', 'jpeg', 'png'])\n",
        "    if img is not None:\n",
        "        image = Image.open(img).convert('RGB')\n",
        "        st.image(image, caption='Uploaded Image', use_column_width=True)\n",
        "\n",
        "        text = st.text_input('Enter Text Prompt (optional):')\n",
        "        # Extended list of keywords and their synonyms\n",
        "        keywords = [\n",
        "        \"same\", \"identical\", \"equal\", \"equivalent\",\n",
        "        \"similar\", \"comparable\", \"analogous\", \"akin\",\n",
        "        \"like\", \"such as\", \"as\", \"resembling\",\n",
        "        \"alike\", \"corresponding\",\"different\"\n",
        "        ]\n",
        "\n",
        "# Split the sentence into words\n",
        "        words = user_prompt.split()\n",
        "\n",
        "# Variable to store the original substring\n",
        "        original_substring = \"\"\n",
        "\n",
        "# Iterate over the words and check for the first keyword match\n",
        "        for i, word in enumerate(words):\n",
        "            if word.lower() in keywords:\n",
        "        # Get the next two words if available\n",
        "                next_words_count = min(2, len(words) - i - 1)  # Ensure we don't go out of range\n",
        "                if next_words_count >= 0:\n",
        "            # Capture the keyword and the next words as a substring\n",
        "                    original_substring = \" \".join(words[i:i+1+next_words_count])\n",
        "\n",
        "            # Print the extracted substring\n",
        "            #print(f\"Extracted Substring: {original_substring}\")\n",
        "# conditional image captioning\n",
        "        text = original_substring   #Similar product\n",
        "\n",
        "\n",
        "        inputs = processor1(image, text, return_tensors=\"pt\").to(\"cuda\", torch.float16)\n",
        "\n",
        "# Generate the output\n",
        "        out = model1.generate(**inputs)\n",
        "\n",
        "# Decode the output and strip the prompt if necessary\n",
        "        generated_text = processor1.decode(out[0], skip_special_tokens=True).strip() #####\n",
        "        #print('PRE',generated_text)\n",
        "# Post-process the output if it contains any part of the prompt\n",
        "# This part is optional if the prompt modification works well\n",
        "        if generated_text.lower().startswith(text.lower()):   #######\n",
        "  #Remove the prompt part from the output\n",
        "            generated_text = generated_text[len(text):].strip()   ########\n",
        "            #print(generated_text)\n",
        "\n",
        "        for i, word in enumerate(words):\n",
        "            if word.lower() in keywords:\n",
        "        # Get the next two words if available\n",
        "            next_words_count = min(2, len(words) - i - 1)  # Ensure we don't go out of range\n",
        "            if next_words_count >= 0:\n",
        "               words[i:i+1+next_words_count] = [generated_text]\n",
        "        query = \" \".join(words)\n",
        "        st.write(\"generated query\")\n",
        "        st.write(query)\n",
        "\n",
        "        results = search_web(query)\n",
        "        display_results(results)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gomz0GUF_-1M",
        "outputId": "4fb815fd-e819-4fae-8002-d56ec6032c4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lipKtWulADXR",
        "outputId": "5975db28-f332-4db5-b54f-d34317e49fe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.247.155.250:8501\u001b[0m\n",
            "\u001b[0m\n",
            "your url is: https://gold-knives-tan.loca.lt\n",
            "2024-10-14 17:46:57.447477: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-10-14 17:46:57.470757: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-10-14 17:46:57.477691: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-10-14 17:46:57.494100: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-10-14 17:46:58.678444: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}